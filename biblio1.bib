@book{sutton1998reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={1998},
  publisher={MIT press}
}

@book{friedman2001elements,
  title={The elements of statistical learning},
  author={Friedman, Jerome and Hastie, Trevor and Tibshirani, Robert},
  volume={1},
  year={2001},
  publisher={Springer series in statistics Springer, Berlin}
}

@article{bubeck2012regret,
  title={Regret analysis of stochastic and nonstochastic multi-armed bandit problems},
  author={Bubeck, S{\'e}bastien and Cesa-Bianchi, Nicolo},
  journal={arXiv preprint arXiv:1204.5721},
  year={2012}
}

@article{agrawal2011analysis,
  title={Analysis of thompson sampling for the multi-armed bandit problem},
  author={Agrawal, Shipra and Goyal, Navin},
  journal={arXiv preprint arXiv:1111.1797},
  year={2011}
}

@article{bubeck2012bandits,
  title={Bandits with heavy tail},
  author={Bubeck, S{\'e}bastien and Cesa-Bianchi, Nicolo and Lugosi, G{\'a}bor},
  journal={arXiv preprint arXiv:1209.1727},
  year={2012}
}

@article{bubeck2013bounded,
  title={Bounded regret in stochastic multi-armed bandits},
  author={Bubeck, S{\'e}bastien and Perchet, Vianney and Rigollet, Philippe},
  journal={arXiv preprint arXiv:1302.1611},
  year={2013}
}

@article{perchet2015batched,
  title={Batched Bandit Problems},
  author={Perchet, Vianney and Rigollet, Philippe and Chassang, Sylvain and Snowberg, Erik},
  journal={arXiv preprint arXiv:1505.00369},
  year={2015}
}

@inproceedings{audibert2010best,
  title={Best arm identification in multi-armed bandits},
  author={Audibert, Jean-Yves and Bubeck, S{\'e}bastien},
  booktitle={COLT-23th COLT-2010},
  pages={13--p},
  year={2010}
}

@article{garivier2011kl,
  title={The KL-UCB algorithm for bounded stochastic bandits and beyond},
  author={Garivier, Aur{\'e}lien and Capp{\'e}, Olivier},
  journal={arXiv preprint arXiv:1102.2490},
  year={2011}
}

@inproceedings{audibert2009minimax,
  title={Minimax policies for adversarial and stochastic bandits},
  author={Audibert, Jean-Yves and Bubeck, S{\'e}bastien},
  booktitle={COLT},
  pages={217--226},
  year={2009}
}

@inproceedings{abbasi2011improved,
  title={Improved algorithms for linear stochastic bandits},
  author={Abbasi-Yadkori, Yasin and P{\'a}l, D{\'a}vid and Szepesv{\'a}ri, Csaba},
  booktitle={NIPS},
  pages={2312--2320},
  year={2011}
}

@article{even2006action,
  title={Action elimination and stopping conditions for the multi-armed bandit and reinforcement learning problems},
  author={Even-Dar, Eyal and Mannor, Shie and Mansour, Yishay},
  journal={JMLR},
  volume={7},
  pages={1079--1105},
  year={2006},
  publisher={JMLR. org}
}

@article{audibert2009exploration,
  title={Exploration--exploitation tradeoff using variance estimates in multi-armed bandits},
  author={Audibert, Jean-Yves and Munos, R{\'e}mi and Szepesv{\'a}ri, Csaba},
  journal={TCS},
  volume={410},
  number={19},
  pages={1876--1902},
  year={2009},
  publisher={Elsevier}
}

@article{auer2010ucb,
  title={UCB revisited: Improved regret bounds for the stochastic multi-armed bandit problem},
  author={Auer, Peter and Ortner, Ronald},
  journal={Periodica Mathematica Hungarica},
  volume={61},
  number={1-2},
  pages={55--65},
  year={2010},
  publisher={Springer}
}

@article{auer2002finite,
  title={Finite-time analysis of the multiarmed bandit problem},
  author={Auer, Peter and Cesa-Bianchi, Nicolo and Fischer, Paul},
  journal={Machine learning},
  volume={47},
  number={2-3},
  pages={235--256},
  year={2002},
  publisher={Springer}
}

@incollection{robbins1952some,
  title={Some aspects of the sequential design of experiments},
  author={Robbins, Herbert},
  booktitle={Herbert Robbins Selected Papers},
  pages={169--177},
  year={1952},
  publisher={Springer}
}

@inproceedings{bubeck2009pure,
  title={Pure exploration in multi-armed bandits problems},
  author={Bubeck, S{\'e}bastien and Munos, R{\'e}mi and Stoltz, Gilles},
  booktitle={ALT},
  pages={23--37},
  year={2009},
  organization={Springer}
}

@article{bubeck2011pure,
  title={Pure exploration in finitely-armed and continuous-armed bandits},
  author={Bubeck, S{\'e}bastien and Munos, R{\'e}mi and Stoltz, Gilles},
  journal={TCS},
  volume={412},
  number={19},
  pages={1832--1852},
  year={2011},
  publisher={Elsevier}
}

@article{lai1985asymptotically,
  title={Asymptotically efficient adaptive allocation rules},
  author={Lai, Tze Leung and Robbins, Herbert},
  journal={Advances in applied mathematics},
  volume={6},
  number={1},
  pages={4--22},
  year={1985},
  publisher={Elsevier}
}

@article{thompson1933likelihood,
  title={On the likelihood that one unknown probability exceeds another in view of the evidence of two samples},
  author={Thompson, William R},
  journal={Biometrika},
  pages={285--294},
  year={1933},
  publisher={JSTOR}
}

@article{auer2002nonstochastic,
  title={The nonstochastic multiarmed bandit problem},
  author={Auer, Peter and Cesa-Bianchi, Nicolo and Freund, Yoav and Schapire, Robert E},
  journal={SICOMP},
  volume={32},
  number={1},
  pages={48--77},
  year={2002},
  publisher={SIAM}
}

@misc{CapGarKau12,
 author={Olivier Cappe and Aurelien Garivier and Emilie Kaufmann},
 title={pymaBandits},
 year={2012},
 note={\url{http://mloss.org/software/view/415/}}
}

@inproceedings{honda2010asymptotically,
  title={An Asymptotically Optimal Bandit Algorithm for Bounded Support Models.},
  author={Honda, Junya and Takemura, Akimichi},
  booktitle={COLT},
  pages={67--79},
  year={2010},
  organization={Citeseer}
}

@article{lattimore2015optimally,
  title={Optimally confident UCB: Improved regret for finite-armed bandits},
  author={Lattimore, Tor},
  journal={arXiv preprint arXiv:1507.07880},
  year={2015}
}

@article{liu2016modification,
  title={Modification of improved upper confidence bounds for regulating exploration in Monte-Carlo tree search},
  author={Liu, Yun-Ching and Tsuruoka, Yoshimasa},
  journal={TCS},
  year={2016},
  publisher={Elsevier}
}

@article{mannor2004sample,
  title={The sample complexity of exploration in the multi-armed bandit problem},
  author={Mannor, Shie and Tsitsiklis, John N},
  journal={JMLR},
  volume={5},
  number={Jun},
  pages={623--648},
  year={2004}
}

@inproceedings{tolpin2012mcts,
  title={MCTS Based on Simple Regret.},
  author={Tolpin, David and Shimony, Solomon Eyal},
  booktitle={AAAI},
  year={2012}
}

@article{auer2002using,
  title={Using confidence bounds for exploitation-exploration trade-offs},
  author={Auer, Peter},
  journal={JMLR},
  volume={3},
  number={Nov},
  pages={397--422},
  year={2002}
}

@article{slivkins2014contextual,
  title={Contextual bandits with similarity information.},
  author={Slivkins, Aleksandrs},
  journal={JMLR},
  volume={15},
  number={1},
  pages={2533--2568},
  year={2014}
}

@inproceedings{li2010contextual,
  title={A contextual-bandit approach to personalized news article recommendation},
  author={Li, Lihong and Chu, Wei and Langford, John and Schapire, Robert E},
  booktitle={WWW},
  pages={661--670},
  year={2010},
  organization={ACM}
}

@inproceedings{langford2008epoch,
  title={The epoch-greedy algorithm for multi-armed bandits with side information},
  author={Langford, John and Zhang, Tong},
  booktitle={NIPS},
  pages={817--824},
  year={2008}
}

@inproceedings{beygelzimer2011contextual,
  title={Contextual Bandit Algorithms with Supervised Learning Guarantees.},
  author={Beygelzimer, Alina and Langford, John and Li, Lihong and Reyzin, Lev and Schapire, Robert E},
  booktitle={AISTATS},
  pages={19--26},
  year={2011}
}

@article{bui2012clustered,
  title={Clustered bandits},
  author={Bui, Loc and Johari, Ramesh and Mannor, Shie},
  journal={arXiv preprint arXiv:1206.4169},
  year={2012}
}

@inproceedings{cesa2013gang,
  title={A gang of bandits},
  author={Cesa-Bianchi, Nicolo and Gentile, Claudio and Zappella, Giovanni},
  booktitle={NIPS},
  pages={737--745},
  year={2013}
}

@inproceedings{gentile2014online,
  title={Online Clustering of Bandits.},
  author={Gentile, Claudio and Li, Shuai and Zappella, Giovanni},
  booktitle={ICML},
  pages={757--765},
  year={2014}
}

@inproceedings{kaufmann2012bayesian,
  title={On Bayesian Upper Confidence Bounds for Bandit Problems.},
  author={Kaufmann, Emilie and Capp{\'e}, Olivier and Garivier, Aur{\'e}lien},
  booktitle={AISTATS},
  pages={592--600},
  year={2012}
}

@inproceedings{hillel2013distributed,
  title={Distributed exploration in multi-armed bandits},
  author={Hillel, Eshcar and Karnin, Zohar S and Koren, Tomer and Lempel, Ronny and Somekh, Oren},
  booktitle={NIPS},
  pages={854--862},
  year={2013}
}

@article{awerbuch2008competitive,
  title={Competitive collaborative learning},
  author={Awerbuch, Baruch and Kleinberg, Robert},
  journal={Journal of Computer and System Sciences},
  volume={74},
  number={8},
  pages={1271--1288},
  year={2008},
  publisher={Elsevier}
}

@article{liu2010distributed,
  title={Distributed learning in multi-armed bandit with multiple players},
  author={Liu, Keqin and Zhao, Qing},
  journal={IEEE Transactions on Signal Processing},
  volume={58},
  number={11},
  pages={5667--5681},
  year={2010},
  publisher={IEEE}
}

@inproceedings{szorenyi2013gossip,
  title={Gossip-based distributed stochastic bandit algorithms.},
  author={Sz{\"o}r{\'e}nyi, Bal{\'a}zs and Busa-Fekete, R{\'o}bert and Heged{\"u}s, Istv{\'a}n and Orm{\'a}ndi, R{\'o}bert and Jelasity, M{\'a}rk and K{\'e}gl, Bal{\'a}zs},
  booktitle={ICML (3)},
  pages={19--27},
  year={2013}
}